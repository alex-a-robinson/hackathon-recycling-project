<!DOCTYPE html>
<html>
<head>
	<title></title>
</head>
<script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
<script type="text/javascript">
	function send() {

		var b64Encoding = canvas.toDataURL().split(',')[1];

		 var json = {
  "requests": [
    {
      "image": {
        "content": b64Encoding
      },
      "features": [
        {
          "type": "LABEL_DETECTION",
          "maxResults": 100,
        }
      ]
    }
  ]
}
	    $.ajax({
		    type: 'POST',
		    url: "https://vision.googleapis.com/v1/images:annotate?key=AIzaSyBEIZqIEqrfWAHPKttG4_iuLDS-ES1zgO8",
		    dataType: 'json',
		    data:  JSON.stringify(json),
		    //Include headers, otherwise you get an odd 400 error.
		    headers: {
		      "Content-Type": "application/json",
		    },

		    success: function(data, textStatus, jqXHR) {
		    	var recycable_items = ["newspapers", "paper", "magazines", "glass", "glass bottles", "jar", "glass jar", "plastic bottle", "bottle", "aluminium", "steel cans", "cans", "can", "aluminium cans", "plastic bags", "plastic wrap", "wrap", "shredded paper", "paper", "clothes", "toys", "furniture", "sharps"]
				var results_summary = [];
				var results = data.responses[0].labelAnnotations;
				var found = false;
		      	for (var i=0; !found && i < results.length; ++i) {
		      		var obj = results[i].description;
		      		results_summary.push(obj);
		      		for (var j = 0; !found && j <= recycable_items.length; ++j) {
		      			var robj = recycable_items[j];
		      			if (robj == obj) {
		      				add_item_to_db(robj);
		      				// found = true;
		      			}
		      		}

		      	}
		    	console.log(results_summary);
		      	console.log(found);
		    },
		    error: function(jqXHR, textStatus, errorThrown) {
		      console.log('ERRORS: ' + textStatus + ' ' + errorThrown + JSON.stringify(jqXHR));
		    }
		  });

	}
	$(document).ready(function() {
		// Grab elements, create settings, etc.
		var video = document.getElementById('video');

		// Get access to the camera!
		if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
		    // Not adding `{ audio: true }` since we only want video now
		    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
		        video.src = window.URL.createObjectURL(stream);
		        video.play();
		    });
		}
		// Elements for taking the snapshot
		var canvas = document.getElementById('canvas');
		var context = canvas.getContext('2d');
		var video = document.getElementById('video');

		// Trigger photo take
		document.getElementById("snap").addEventListener("click", function() {
			context.drawImage(video, 0, 0, 640, 480);
			send();
		});
	});
</script>
<script src="/js/main.js"></script>
<body>
	<script src="https://www.gstatic.com/firebasejs/4.2.0/firebase.js"></script>
	<script>
    // Initialize Firebase
    var config = {
      apiKey: "AIzaSyAzSdS0FUN6ULzm_JjQh26eHSBkbMGaIZo",
      authDomain: "hackathon-12cd5.firebaseapp.com",
      databaseURL: "https://hackathon-12cd5.firebaseio.com",
      projectId: "hackathon-12cd5",
      storageBucket: "hackathon-12cd5.appspot.com",
      messagingSenderId: "388474147548"
    };
    firebase.initializeApp(config);
  </script>
	<!--
		Ideally these elements aren't created until it's confirmed that the 
		client supports video/camera, but for the sake of illustrating the 
		elements involved, they are created with markup (not JavaScript)
	-->
	<video id="video" width="640" height="480" autoplay></video>
	<button id="snap">Snap Photo</button>
	<canvas id="canvas" width="640" height="480"></canvas>

</body>
</html>

